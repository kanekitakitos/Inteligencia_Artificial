# Problem 4: 2 or 3? - Classifica√ß√£o Bin√°ria com MLP

**Autor:** Brandon Mejia

**Data:** Dezembro 2025

---

## üìù Descri√ß√£o do Problema e Algoritmo

O objetivo deste laborat√≥rio √© desenvolver um classificador bin√°rio capaz de distinguir entre os d√≠gitos manuscritos **'2'** e **'3'**. O problema utiliza um subconjunto simplificado do dataset MNIST.

* **Dataset:** O ficheiro fornecido (`dataset.csv`) cont√©m **800 exemplos** (imagens).
* **Dimens√µes:** Cada imagem possui $20 \times 20$ pixeis, resultando em 400 valores de entrada por exemplo.
* **Modelo:** A solu√ß√£o baseia-se numa rede *Multi-Layer Perceptron* (MLP), reaproveitando a implementa√ß√£o do Problema 3, adaptada para classifica√ß√£o bin√°ria com o algoritmo de *Backpropagation*.

---

## üìä An√°lise Explorat√≥ria de Dados

Para compreender a complexidade intr√≠nseca do problema, realiz√°mos uma an√°lise estat√≠stica e visual dos dados.

### Separabilidade Linear (PCA)
Projet√°mos os dados num espa√ßo 2D usando a An√°lise de Componentes Principais (PCA).

![PCA Graph](assets/graph_0.png)

> **Observa√ß√£o:** A visualiza√ß√£o PCA mostra que, embora existam agrupamentos, as classes n√£o s√£o linearmente separ√°veis na fronteira. Isto sugere que precisamos de $N$ neur√≥nios na camada oculta, situando-se no intervalo $2 \le N \le 6$.

### Topologia e Mapa de Diferen√ßa
Calcul√°mos a imagem m√©dia de cada classe e a diferen√ßa absoluta entre elas.

| M√©dia '2' | Heatmap Diferen√ßa | M√©dia '3' |
| :---: | :---: | :---: |
| ![Media 2](assets/graph_1.png) | ![Heatmap](assets/graph_2.png) | ![Media 3](assets/graph_3.png) |

> O mapa de calor (centro) revela as zonas de maior vari√¢ncia entre as m√©dias das duas classes. A complexidade desta topologia dita a necessidade de neur√≥nios na camada oculta.

---

## üß† Arquitetura da Rede

A defini√ß√£o da arquitetura n√£o seguiu uma abordagem est√°tica. Compreendemos que a topologia da rede est√° intrinsecamente ligada √† natureza dos dados de treino:

* **Dados ruidosos:** Exigem uma camada oculta mais vasta para capturar as nuances.
* **Dados limpos:** Permitem o uso de menos neur√≥nios, favorecendo a generaliza√ß√£o.

Desta forma, a nossa arquitetura base define-se por:

* **Camada de Entrada:** 400 neur√≥nios (Imagem $20 \times 20$).
* **Camada Oculta:** Vari√°vel ($N$ neur√≥nios), onde o intervalo experimental testado foi entre **6 e 2 neur√≥nios**.
* **Camada de Sa√≠da:** 1 neur√≥nio (Ativa√ß√£o Sigmoide).

---

## üõ† Op√ß√µes de Design e Metodologia

### A Classe `HyperparameterTuner`
Para resolver a depend√™ncia entre a complexidade dos dados e a arquitetura, desenvolvemos a classe **`HyperparameterTuner`**. Esta ferramenta automatiza a experimenta√ß√£o, testando iterativamente diferentes topologias e hiperpar√¢metros (Learning Rate, Momentum).

### Funcionalidades Avan√ßadas (MLP)
A implementa√ß√£o inclui melhorias essenciais:
1.  **Normaliza√ß√£o:** Inputs estritamente normalizados para o intervalo $[0, 1]$.
2.  **Decodifica√ß√£o da Sa√≠da:** Definimos um limiar (*threshold*) de 0.5.
    * Valor $< 0.5$: Classificado como **2**.
    * Valor $\ge 0.5$: Classificado como **3**.
3.  **Momentum e Regulariza√ß√£o L2:** Utilizados para acelerar a converg√™ncia.

### Estrat√©gia de Treino
* **Paragem:** Utiliz√°mos *Early Stopping* com valida√ß√£o cruzada (80/20).
* **Estabilidade (Batch Size):** Definimos o *batch size* em **32**. Esta escolha revelou-se fundamental para estabilizar a aprendizagem e reduzir a oscila√ß√£o do erro (MSE), evitando saltos abruptos nos pesos.

### Scripts Auxiliares
Os scripts utilizados para pr√©-processamento e valida√ß√£o foram:
* `analisador_dados.py`: Pr√©-processamento e visualiza√ß√£o.
* `testar_dados.py`: Testes e valida√ß√£o.

O c√≥digo fonte completo e as ferramentas utilizadas podem ser consultados no reposit√≥rio:

[**üîó Reposit√≥rio GitHub - Ferramentas e Scripts**](https://github.com/kanekitakitos/Inteligencia_Artificial/tree/main/04%20-%20MLP%20identify%203%20and%202/tools-for-data)

---

## üìà Resultados e Discuss√£o

Os resultados demonstraram o comportamento da rede face √† complexidade:
* **Redes maiores (5-6 neur√≥nios):** Converg√™ncia r√°pida, mas maior oscila√ß√£o no teste.
* **Redes menores (2-3 neur√≥nios):** Curva de aprendizagem mais suave e generaliza√ß√£o superior.
* **Acur√°cia Final:** O modelo selecionado atinge consistentemente resultados no intervalo **99% - 100%**.

![Curva MSE](assets/graph_4.png)
*Curva de aprendizagem baseada nos dados experimentais recolhidos.*

---

## üëÅÔ∏è Visualiza√ß√£o do Pr√©-processamento

O foco desta experimenta√ß√£o foi avaliar a robustez da rede manipulando a vari√¢ncia dos dados (introduzindo ru√≠do, rota√ß√µes e cortes).

| | | | |
|:---:|:---:|:---:|:---:|
| ![Img 0](assets/graph_5.png)<br><sub>Corte 7 bits (cima)</sub> | ![Img 1](assets/graph_6.png)<br><sub>Transla√ß√£o +5</sub> | ![Img 2](assets/graph_7.png)<br><sub>Ru√≠do Q2 e Q4</sub> | ![Img 3](assets/graph_8.png)<br><sub>Ru√≠do Circular</sub> |
| ![Img 4](assets/graph_9.png)<br><sub>Rota√ß√£o -10¬∫</sub> | ![Img 5](assets/graph_10.png)<br><sub>Corte 7 bits (baixo)</sub> | ![Img 6](assets/graph_11.png)<br><sub>Linhas Horiz. (45%)</sub> | ![Img 7](assets/graph_12.png)<br><sub>Linhas Vert. (90%)</sub> |

---

## üèÜ Conclus√µes Principais

A solu√ß√£o final resolve o problema de classifica√ß√£o com distin√ß√£o, respeitando o princ√≠pio de usar a complexidade apenas quando estritamente necess√°ria.

### Desempenho no Mooshak
Com a configura√ß√£o otimizada, o grupo atingiu uma classifica√ß√£o de **92.25%** na plataforma Mooshak (modelo `src/models/92_250`).

**Estrat√©gia Vencedora:**
A estrat√©gia que garantiu o melhor desempenho consistiu em **cortar os primeiros 7 bits** (de cima para baixo) de cada imagem. Esta t√©cnica permitiu que a rede se focasse exclusivamente nas partes distintivas dos d√≠gitos, ignorando a zona superior das imagens que continha pouca informa√ß√£o relevante.

---

## üìö Refer√™ncias Bibliogr√°ficas

1. [MNIST Database](https://wiki.pathmind.com/mnist)
2. Enunciado do Projeto: IA 2025-26 Lab 4.
3. [Milvus.io - Adam and RMSprop](https://milvus.io/ai-quick-reference/how-do-optimizers-like-adam-and-rmsprop-work)
4. [AIShort - Choosing the Right Optimizer](https://aishort.co.uk/choosing-the-right-optimizer-for-neural-networks-a-practical-guide/)
5. [GeeksforGeeks - Adam Optimizer](https://www.geeksforgeeks.org/deep-learning/adam-optimizer/)
6. [Innovatiana - Activation Functions](https://www.innovatiana.com/es/post/activation-function-in-ai)
7. [DataCamp - Normalization](https://www.datacamp.com/pt/tutorial/normalization-in-machine-learning)
8. [GitHub - Curvature-Orientation-MLP](https://github.com/Meetra21/Curvature-Orientation-MLP)
9. [Jones (2021) - Publication](https://www.ilenna.com/publication/jones-2021/Jones-2021.pdf)
10. [arXiv:1905.12135](https://arxiv.org/pdf/1905.12135)
11. [Reddit - Tanh vs Sigmoid](https://www.reddit.com/r/MachineLearning/comments/3x9kld/tanh_or_sigmoid_for_simple_nn_in_mnist/)
12. [Google Developers - Numerical Data Normalization](https://developers.google.com/machine-learning/crash-course/numerical-data/normalization?hl=pt-br)
13. [Exxact Corp - Maximizing AI Efficiency](https://www.exxactcorp.com/blog/deep-learning-ai/maximizing-ai-efficiency-tuning-and-regulation)
14. [Machine Learning Mastery - Data Scaling](https://machinelearningmastery.com/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling/)
15. [Scikit-Learn - Neural Networks](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)
16. [arXiv:2506.17826](https://arxiv.org/html/2506.17826v1)
17. [Ameer Saleem - Stochastic Gradient Descent](https://ameersaleem.substack.com/p/stochastic-gradient-descent-and-mini)
18. [LunarTech - Gradient Descent Comparison](https://www.lunartech.ai/blog/gradient-descent-vs-mini-batch-gradient-descent-vs-stochastic-gradient-descent-an-expert-comparison)